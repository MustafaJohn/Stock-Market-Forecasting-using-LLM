{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1a0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimesFM v1.2.0. See https://github.com/google-research/timesfm/blob/master/README.md for updated APIs.\n",
      "Loaded Jax TimesFM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amaan\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PyTorch TimesFM.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from timesfm import TimesFm, TimesFmHparams, TimesFmCheckpoint\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f890bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and settings\n",
    "\n",
    "# Parameters for data split\n",
    "WINDOW = 5  # rolling window size to use as predictors (for TimesFM window size should be multiple of 32 - input patch length)\n",
    "DATE_COL = 'DlyCalDt'\n",
    "ID_COL = 'PERMNO'\n",
    "TARGET_COL = 'ExcessReturn'\n",
    "\n",
    "# Estimation (in sample) period dates\n",
    "in_sample_start_date = pd.to_datetime(\"2000-01-01\")\n",
    "in_sample_end_date = pd.to_datetime(\"2015-12-31\")\n",
    "\n",
    "# Out-of-sample period dates\n",
    "out_sample_start_date = pd.to_datetime(\"2016-01-01\")\n",
    "out_sample_end_date = pd.to_datetime(\"2024-12-31\")\n",
    "\n",
    "# Use GPU if available, else default to using CPU\n",
    "device_map = \"cpu\" \n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f772f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned and filtered data files for in sample and out of sample periods into a pandas DataFrames\n",
    "in_sample_df = pd.read_csv(\"../Cleaned Datasets/in_sample_cleaned.csv\")\n",
    "out_sample_df = pd.read_csv(\"../Cleaned Datasets/out_sample_cleaned.csv\")\n",
    "\n",
    "\n",
    "# Ensure the date columns are in datetime format\n",
    "in_sample_df[DATE_COL] = pd.to_datetime(in_sample_df[DATE_COL])\n",
    "out_sample_df[DATE_COL] = pd.to_datetime(out_sample_df[DATE_COL])\n",
    "\n",
    "in_sample_df = in_sample_df[[ID_COL, DATE_COL, TARGET_COL]].dropna()\n",
    "out_sample_df = out_sample_df[[ID_COL, DATE_COL, TARGET_COL]].dropna()\n",
    "\n",
    "in_sample_df = in_sample_df.sort_values([ID_COL, DATE_COL]).reset_index(drop=True)\n",
    "out_sample_df = out_sample_df.sort_values([ID_COL, DATE_COL]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d877f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199550 entries, 0 to 199549\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   PERMNO        199550 non-null  int64         \n",
      " 1   DlyCalDt      199550 non-null  datetime64[ns]\n",
      " 2   ExcessReturn  199550 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 4.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112400 entries, 0 to 112399\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   PERMNO        112400 non-null  int64         \n",
      " 1   DlyCalDt      112400 non-null  datetime64[ns]\n",
      " 2   ExcessReturn  112400 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "in_sample_df.info()\n",
    "out_sample_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be1e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique stocks: 50\n"
     ]
    }
   ],
   "source": [
    "stocks_permno = in_sample_df[\"PERMNO\"].unique().tolist()\n",
    "print(f\"Number of unique stocks: {len(stocks_permno)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36dcb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spit data into estimation (in-sample) and out-of-sample data\n",
    "df_train = in_sample_df.copy()\n",
    "df_test = out_sample_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd22b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199550 entries, 0 to 199549\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   PERMNO        199550 non-null  int64         \n",
      " 1   DlyCalDt      199550 non-null  datetime64[ns]\n",
      " 2   ExcessReturn  199550 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 4.6 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112400 entries, 0 to 112399\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   PERMNO        112400 non-null  int64         \n",
      " 1   DlyCalDt      112400 non-null  datetime64[ns]\n",
      " 2   ExcessReturn  112400 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 2.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_train.info())\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e1bbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling window for predictors for Bolt models\n",
    "\n",
    "combined_df = pd.concat([in_sample_df, out_sample_df])\n",
    "combined_df = combined_df.sort_values([ID_COL, DATE_COL]).reset_index(drop=True)\n",
    "combined_df[DATE_COL] = pd.to_datetime(combined_df[DATE_COL])\n",
    "\n",
    "contexts = []\n",
    "targets = []\n",
    "records = []\n",
    "\n",
    "for id, grp in combined_df.groupby(ID_COL):\n",
    "    values = grp[TARGET_COL].values\n",
    "    dates = grp[DATE_COL].values\n",
    "\n",
    "    for i in range(len(values) - WINDOW):\n",
    "        pred_date = dates[i + WINDOW]\n",
    "        if pred_date >= pd.to_datetime(\"2016-01-01\"):\n",
    "            contexts.append(torch.tensor(values[i:i+WINDOW], dtype=torch.float32, device=device))\n",
    "            targets.append(values[i+WINDOW])\n",
    "            records.append({\n",
    "                ID_COL: id,\n",
    "                TARGET_COL: values[i+WINDOW],\n",
    "                DATE_COL: pred_date\n",
    "            })\n",
    "\n",
    "#contexts = np.array(contexts).astype(np.float32)  # shape = (N, WINDOW)\n",
    "#targets = np.array(targets).astype(np.float32)    # shape = (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2517115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.Series(targets)\n",
    "\n",
    "results = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f581bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Function to Calculate Predictive-R2 Used in the Finance Literature\n",
    "def r2(y_true, y_pred):\n",
    "    return 1-(((y_true-y_pred)**2).sum()/(y_true**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef9aa6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directional Accuracy Split\n",
    "def directional_accuracy(y_true, y_pred):\n",
    "    sign_match = np.sign(y_true) == np.sign(y_pred)\n",
    "    up_da = sign_match[y_true > 0].mean() if np.any(y_true > 0) else np.nan\n",
    "    down_da = sign_match[y_true < 0].mean() if np.any(y_true < 0) else np.nan\n",
    "    return up_da, down_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53ea6a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Zero Shot TimesFM-1.0-200M\n",
    "tfm1 = TimesFm(\n",
    "    hparams = TimesFmHparams(\n",
    "        context_len = 32,\n",
    "        horizon_len = 1,\n",
    "        input_patch_len = 32,      # fixed for 200m model\n",
    "        output_patch_len = 128,    # fixed for 200m model\n",
    "        num_layers = 20,           # fixed for 200m model\n",
    "        model_dims = 1280,         # fixed for 200m model\n",
    "        backend = device_map       \n",
    "        ),\n",
    "    checkpoint = TimesFmCheckpoint(huggingface_repo_id=\"google/timesfm-1.0-200m-pytorch\")\n",
    "    )\n",
    "freqs = [0] * len(contexts)\n",
    "preds, _ = tfm1.forecast(contexts, freq=freqs)\n",
    "\n",
    "y_tfm1 = pd.Series(preds.reshape([-1,]))\n",
    "\n",
    "results['y_tfm1'] = y_tfm1\n",
    "r2_tfm1  = r2(y_test, y_tfm1)\n",
    "mse_tfm1 = mean_squared_error(y_test, y_tfm1)\n",
    "mae_tfm1 = mean_absolute_error(y_test, y_tfm1)\n",
    "da_tfm1 = (np.sign(y_test) == np.sign(y_tfm1)).mean()\n",
    "up_da_tfm1, down_da_tfm1 = directional_accuracy(y_test, y_tfm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fcd0f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 2491.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Zero Shot TimesFM-2.0-500M\n",
    "tfm2 = TimesFm(\n",
    "    hparams = TimesFmHparams(\n",
    "        context_len = 32,\n",
    "        horizon_len = 1,\n",
    "        input_patch_len = 32,      # fixed for 500m model\n",
    "        output_patch_len = 128,    # fixed for 500m model\n",
    "        num_layers = 50,           # fixed for 500m model\n",
    "        model_dims = 1280,         # fixed for 500m model\n",
    "        backend = device_map       \n",
    "        ),\n",
    "    checkpoint = TimesFmCheckpoint(huggingface_repo_id=\"google/timesfm-2.0-500m-pytorch\")\n",
    "    )\n",
    "\n",
    "freqs = [0] * len(contexts)\n",
    "preds, _ = tfm2.forecast(contexts, freq=freqs)\n",
    "\n",
    "y_tfm2 = pd.Series(preds.reshape([-1,]))\n",
    "\n",
    "results['y_tfm2'] = y_tfm2\n",
    "r2_tfm2  = r2(y_test, y_tfm2)\n",
    "mse_tfm2 = mean_squared_error(y_test, y_tfm2)\n",
    "mae_tfm2 = mean_absolute_error(y_test, y_tfm2)\n",
    "da_tfm2 = (np.sign(y_test) == np.sign(y_tfm2)).mean()\n",
    "up_da_tfm2, down_da_tfm2 = directional_accuracy(y_test, y_tfm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f64227eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collating Results\n",
    "\n",
    "results_matrix = [{\n",
    "        \"Model\": \"TimesFM-1.0-200M\",\n",
    "        \"R-squared\": r2_tfm1,\n",
    "        \"MSE\": mse_tfm1,\n",
    "        \"MAE\": mae_tfm1,\n",
    "        \"Direction Accuracy\": da_tfm1,\n",
    "        \"Up Directional Accuracy\": up_da_tfm1,\n",
    "        \"Down Directional Accuracy\": down_da_tfm1\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"TimesFM-2.0-500M\",\n",
    "        \"R-squared\": r2_tfm2,\n",
    "        \"MSE\": mse_tfm2,\n",
    "        \"MAE\": mae_tfm2,\n",
    "        \"Direction Accuracy\": da_tfm2,\n",
    "        \"Up Directional Accuracy\": up_da_tfm2,\n",
    "        \"Down Directional Accuracy\": down_da_tfm2\n",
    "    }]\n",
    "\n",
    "results_matrix_df = pd.DataFrame(results_matrix)\n",
    "results_matrix_df.to_csv(\"timesfm(5-day)_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9adb73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Prediction Results\n",
    "results.to_csv(\"timesfm(5-day)\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
